# Retrieval Augmented Generation(RAG)

## What

Retrieval augmented generation, or RAG, is an architectural approach that can improve the efficacy of large language 
model (LLM) applications by **leveraging custom data**. This is done by **retrieving** data/documents relevant to a question 
or task and providing them as **context** for the LLM. RAG has shown success in support chatbots and Q&A systems that 
need to maintain up-to-date information or access domain-specific knowledge.

## Why

- LLMs can't access new information post-training, leading to potential inaccuracies or **outdated** responses since 
  they're trained on static datasets and lack the ability to update their knowledge base.

- Effective AI applications, like customer support or internal Q&A bots, require **access** to specific organizational 
  data to provide relevant responses, posing a challenge without retraining the LLMs.


  
## RAG applications

### Example architecture

Below is one commonly adopted workflow.

## Misc

### Vector Database

A vector database indexes and stores vector embeddings for fast retrieval and similarity search.

<img width="981" alt="image" src="https://gist.github.com/assets/47337188/8c91df7d-2d62-4a9c-be02-fc495a9cc069">

<img width="948" alt="image" src="https://gist.github.com/assets/47337188/26c049f2-9bf6-4890-8cbf-9da776a2b598">


## References

https://arxiv.org/pdf/2005.11401

https://www.databricks.com/glossary/retrieval-augmented-generation-rag

What is Retrieval-Augmented Generation (RAG)?
https://www.youtube.com/watch?v=T-D1OfcDW1M

Vector Databases simply explained! (Embeddings & Indexes)
https://www.youtube.com/watch?v=v_RvESp1frs